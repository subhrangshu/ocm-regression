{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mlp\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "import math\n",
    "print(1)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Activation, Flatten, Dense, Reshape\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import os\n",
    "import pickle\n",
    "from scipy import stats\n",
    "print(2)\n",
    "from keras.utils import plot_model\n",
    "from numpy import array\n",
    "from keras.layers.convolutional import Conv1D, Conv2D\n",
    "from keras.layers.convolutional import MaxPooling1D, MaxPooling2D\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(3)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "print(4)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib\n",
    "print(5)\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors.classification import RadiusNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "print(6)\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, ARDRegression, MultiTaskElasticNet, HuberRegressor, RANSACRegressor, TheilSenRegressor, PoissonRegressor, TweedieRegressor, GammaRegressor, PassiveAggressiveRegressor, ridge_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import SGDClassifier, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor, GradientBoostingRegressor, IsolationForest, RandomTreesEmbedding, StackingRegressor, VotingRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.isotonic import isotonic_regression\n",
    "from sklearn.dummy import DummyRegressor\n",
    "print(7)\n",
    "from sklearn.neural_network.multilayer_perceptron import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import median_absolute_error, mean_squared_error, r2_score, explained_variance_score, max_error, mean_squared_log_error, mean_poisson_deviance, mean_gamma_deviance, mean_tweedie_deviance\n",
    "print(8)\n",
    "\n",
    "import os\n",
    "#os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Activation, Flatten, Dense, Reshape\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(9)\n",
    "import os\n",
    "import pickle\n",
    "from keras.utils import plot_model\n",
    "from numpy import array\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D, MaxPooling2D\n",
    "import time\n",
    "print(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "look_back=1\n",
    "def evaluate_model(model, x, y):\n",
    "    y_pred = scalerY.inverse_transform(model.predict(x).reshape(-1, 1))\n",
    "    y = scalerY.inverse_transform(y.reshape(-1, 1))\n",
    "    \n",
    "    try:\n",
    "        print('Mean Prediction Score:', mean_prediction_score(y, y_pred))\n",
    "    except:\n",
    "        None\n",
    "    try:\n",
    "        print('Mean squared Error:', mean_squared_error(y, y_pred))\n",
    "    except:\n",
    "        None\n",
    "    try:\n",
    "        print('Median absolute error:', median_absolute_error(y, y_pred))\n",
    "    except:\n",
    "        None\n",
    "    try:\n",
    "        print('R2:', r2_score(y, y_pred))\n",
    "    except:\n",
    "        None\n",
    "    try:\n",
    "        print('Explained Variance:', explained_variance_score(y, y_pred))\n",
    "    except:\n",
    "        None\n",
    "    try:\n",
    "        print('Max Error:', max_error(y, y_pred))\n",
    "    except:\n",
    "        None\n",
    "    try:\n",
    "        print('Mean Squared Log Error:', mean_squared_log_error(y, y_pred))\n",
    "    except:\n",
    "        None\n",
    "    try:\n",
    "        print('Mean poisson deviance:', mean_poisson_deviance(y, y_pred))\n",
    "    except:\n",
    "        None\n",
    "    try:\n",
    "        print('Mean Gamma Deviance:', mean_gamma_deviance(y, y_pred))\n",
    "    except:\n",
    "        None\n",
    "    try:\n",
    "        print('Mean Tweedie Deviance:', mean_tweedie_deviance(y, y_pred))\n",
    "\n",
    "    except:\n",
    "        None\n",
    "        \n",
    "def mean_prediction_score(RUL_real, RUL_pred):\n",
    "    d = RUL_pred - RUL_real\n",
    "    \n",
    "    return (np.sum(np.exp(d[d >= 0] / 13) - 1) +\n",
    "            np.sum(np.exp(-1 * d[d < 0] / 10) - 1)) / len(RUL_real)\n",
    "\n",
    "\n",
    "def preprocess():\n",
    "    global X\n",
    "    global Y\n",
    "    global train_size\n",
    "    global test_size\n",
    "    global X_train\n",
    "    global Y_train\n",
    "    global X_test\n",
    "    global Y_test\n",
    "    global scalerX\n",
    "    global scalerY\n",
    "    \n",
    "    X = read_csv(link, usecols=[1,2,5,6,8,9,10,12,13,15,18,20,21,22,23], engine='python')\n",
    "    Y = read_csv(link, usecols=[7], engine='python')\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 3)\n",
    "    \n",
    "    scalerX = MinMaxScaler(feature_range=(0, 1))\n",
    "    scalerY = MinMaxScaler(feature_range=(0, 1))\n",
    "    scalerX = scalerX.fit(pd.concat([X_train,X_test],axis=0))\n",
    "    scalerY = scalerY.fit(pd.concat([Y_train,Y_test],axis=0))\n",
    "    \n",
    "    X_train = scalerX.transform(X_train)\n",
    "    X_test = scalerX.transform(X_test)\n",
    "    Y_train = scalerY.transform(Y_train)\n",
    "    Y_test = scalerY.transform(Y_test)\n",
    "\n",
    "    Y_train = Y_train.ravel()\n",
    "    Y_test = Y_test.ravel()\n",
    "\n",
    "    look_back = 1\n",
    "    #Y_train = create_dataset(Y_train,look_back)[1]\n",
    "    #Y_test = create_dataset(Y_test,look_back)[1]\n",
    "\n",
    "    X_train = numpy.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_test = numpy.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "    \n",
    "\n",
    "def testModel(model):\n",
    "    global trainPredict\n",
    "    global testPredict\n",
    "    trainPredict = model.predict(X_train)\n",
    "    a = time.time()\n",
    "    testPredict = model.predict(X_test)\n",
    "    b = time.time()\n",
    "    print(\"Prediction Time: \" + str(b-a))\n",
    "    \n",
    "    evaluate_model(model, X_train, Y_train.ravel())\n",
    "    evaluate_model(model, X_test, Y_test.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = ''\n",
    "filename = '../Extended_Work/Extracted Datasets/All Loc Combined.csv'\n",
    "link = directory + filename #TODOzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "model = SVR()\n",
    "a = time.time()\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"Training time for Support Vector Regressor: \" + str(time.time()-a))\n",
    "testModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "model = LinearRegression()\n",
    "a = time.time()\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"Training time for Linear Regression: \" + str(time.time()-a))\n",
    "testModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "model = SGDRegressor()\n",
    "a = time.time()\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"Training time for SGD Regressor: \" + str(time.time()-a))\n",
    "testModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "model = ARDRegression()\n",
    "a = time.time()\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"Training time for ARD Regression: \" + str(time.time()-a))\n",
    "testModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "model = ElasticNet()\n",
    "a = time.time()\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"Training time for ElasticNet: \" + str(time.time()-a))\n",
    "testModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "model = HuberRegressor(max_iter=1000)\n",
    "a = time.time()\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"Training time for Huber Regressor: \" + str(time.time()-a))\n",
    "testModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "model = RANSACRegressor()\n",
    "a = time.time()\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"Training time for RANSACRegressor: \" + str(time.time()-a))\n",
    "testModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "model = PoissonRegressor()\n",
    "a = time.time()\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"Training time for PoissonRegressor: \" + str(time.time()-a))\n",
    "testModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "model = TweedieRegressor()\n",
    "a = time.time()\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"Training time for TweedieRegressor: \" + str(time.time()-a))\n",
    "testModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "model = PassiveAggressiveRegressor()\n",
    "a = time.time()\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"Training time for PassiveAggressiveRegressor: \" + str(time.time()-a))\n",
    "testModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "clf = Pipeline([('poly', PolynomialFeatures(degree=3)),('linear', LinearRegression(fit_intercept=False))])\n",
    "a = time.time()\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "print(\"Training time for Pipeline Linear Regression: \" + str(time.time()-a))\n",
    "testModel(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainPredict = model.predict(X_train)\n",
    "#ytrain = pd.DataFrame(Y_train)\n",
    "#ytrain.columns = ['Original']\n",
    "#trainPredict = model.predict(X_train)\n",
    "#trainPredict = pd.DataFrame(trainPredict)\n",
    "#trainPredict.columns = ['Predicted']\n",
    "#combined = pd.concat([ytrain,trainPredict],axis=1)\n",
    "#combined.to_csv('Pipelined on Train data.csv')\n",
    "#combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "clf = linear_model.BayesianRidge()\n",
    "a = time.time()\n",
    "a = time.time()\n",
    "clf = clf.fit(X_train, Y_train.ravel())\n",
    "b = time.time()\n",
    "print(\"Train time for BayesianRidge:\" + str(b-a))\n",
    "testModel(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "clf = KNeighborsRegressor(n_neighbors=3)\n",
    "a = time.time()\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "print(\"Training time for KNR: \" + str(time.time()-a))\n",
    "testModel(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "clf = MLPRegressor(random_state=1, max_iter=10000)\n",
    "a = time.time()\n",
    "clf = clf.fit(X_train, Y_train.ravel())\n",
    "print(\"Training time for MLPR: \" + str(time.time()-a))\n",
    "testModel(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainPredict = model.predict(X_train)\n",
    "ytrain = pd.DataFrame(Y_train)\n",
    "ytrain.columns = ['Original']\n",
    "trainPredict = clf.predict(X_train)\n",
    "trainPredict = pd.DataFrame(trainPredict)\n",
    "trainPredict.columns = ['Predicted']\n",
    "combined = pd.concat([ytrain,trainPredict],axis=1)\n",
    "combined.to_csv('MLPR on Train data.csv')\n",
    "#combined\n",
    "\n",
    "#trainPredict = model.predict(X_train)\n",
    "ytest = pd.DataFrame(Y_test)\n",
    "ytest.columns = ['Original']\n",
    "testPredict = clf.predict(X_test)\n",
    "testPredict = pd.DataFrame(testPredict)\n",
    "testPredict.columns = ['Predicted']\n",
    "combined = pd.concat([ytest,testPredict],axis=1)\n",
    "combined.to_csv('MLPR on Test data.csv')\n",
    "#combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "a = time.time()\n",
    "model = model.fit(X_train, Y_train.ravel())\n",
    "print(\"Training time for RFR: \" + str(time.time()-a))\n",
    "testModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainPredict = model.predict(X_train)\n",
    "ytrain = pd.DataFrame(scalerY.inverse_transform(Y_train.reshape(-1, 1)))\n",
    "ytrain.columns = ['Original']\n",
    "trainPredict = model.predict(X_train)\n",
    "trainPredict = pd.DataFrame(scalerY.inverse_transform(trainPredict.reshape(-1, 1)))\n",
    "trainPredict.columns = ['Predicted']\n",
    "combined = pd.concat([ytrain,trainPredict],axis=1)\n",
    "combined.to_csv('RFR on Train data.csv')\n",
    "\n",
    "#trainPredict = model.predict(X_train)\n",
    "ytest = pd.DataFrame(scalerY.inverse_transform(Y_test.reshape(-1, 1)))\n",
    "ytest.columns = ['Original']\n",
    "testPredict = model.predict(X_test)\n",
    "testPredict = pd.DataFrame(scalerY.inverse_transform(testPredict.reshape(-1, 1)))\n",
    "testPredict.columns = ['Predicted']\n",
    "combined = pd.concat([ytest,testPredict],axis=1)\n",
    "combined.to_csv('RFR on Test data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "clf = tree.DecisionTreeRegressor()\n",
    "a = time.time()\n",
    "clf = clf.fit(X_train,  Y_train)\n",
    "print(\"Training time for DTR: \" + str(time.time()-a))\n",
    "testModel(clf)\n",
    "#evaluate_model(clf, x_test_svr, y_test_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainPredict = model.predict(X_train)\n",
    "ytrain = pd.DataFrame(Y_train)\n",
    "ytrain.columns = ['Original']\n",
    "trainPredict = clf.predict(X_train)\n",
    "trainPredict = pd.DataFrame(trainPredict)\n",
    "trainPredict.columns = ['Predicted']\n",
    "combined = pd.concat([ytrain,trainPredict],axis=1)\n",
    "combined.to_csv('DTR on Train data.csv')\n",
    "#combined\n",
    "\n",
    "#trainPredict = model.predict(X_train)\n",
    "ytest = pd.DataFrame(Y_test)\n",
    "ytest.columns = ['Original']\n",
    "testPredict = clf.predict(X_test)\n",
    "testPredict = pd.DataFrame(testPredict)\n",
    "testPredict.columns = ['Predicted']\n",
    "combined = pd.concat([ytest,testPredict],axis=1)\n",
    "combined.to_csv('DTR on Test data.csv')\n",
    "#combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "model = AdaBoostRegressor()\n",
    "a = time.time()\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"Training time for AdaBoostRegressor: \" + str(time.time()-a))\n",
    "testModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "model = BaggingRegressor()\n",
    "a = time.time()\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"Training time for BaggingRegressor: \" + str(time.time()-a))\n",
    "testModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainPredict = model.predict(X_train)\n",
    "ytrain = pd.DataFrame(scalerY.inverse_transform(Y_train.reshape(-1, 1)))\n",
    "ytrain.columns = ['Original']\n",
    "trainPredict = model.predict(X_train)\n",
    "trainPredict = pd.DataFrame(scalerY.inverse_transform(trainPredict.reshape(-1, 1)))\n",
    "trainPredict.columns = ['Predicted']\n",
    "combined = pd.concat([ytrain,trainPredict],axis=1)\n",
    "combined.to_csv('BaggingRegressor on Train data.csv')\n",
    "\n",
    "#trainPredict = model.predict(X_train)\n",
    "ytest = pd.DataFrame(scalerY.inverse_transform(Y_test.reshape(-1, 1)))\n",
    "ytest.columns = ['Original']\n",
    "testPredict = model.predict(X_test)\n",
    "testPredict = pd.DataFrame(scalerY.inverse_transform(testPredict.reshape(-1, 1)))\n",
    "testPredict.columns = ['Predicted']\n",
    "combined = pd.concat([ytest,testPredict],axis=1)\n",
    "combined.to_csv('BaggingRegressor on Test data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "model = ExtraTreesRegressor()\n",
    "a = time.time()\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"Training time for ExtraTreesRegressor: \" + str(time.time()-a))\n",
    "testModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainPredict = model.predict(X_train)\n",
    "ytrain = pd.DataFrame(scalerY.inverse_transform(Y_train.reshape(-1, 1)))\n",
    "ytrain.columns = ['Original']\n",
    "trainPredict = model.predict(X_train)\n",
    "trainPredict = pd.DataFrame(scalerY.inverse_transform(trainPredict.reshape(-1, 1)))\n",
    "trainPredict.columns = ['Predicted']\n",
    "combined = pd.concat([ytrain,trainPredict],axis=1)\n",
    "combined.to_csv('ExtraTrees on Train data.csv')\n",
    "\n",
    "#trainPredict = model.predict(X_train)\n",
    "ytest = pd.DataFrame(scalerY.inverse_transform(Y_test.reshape(-1, 1)))\n",
    "ytest.columns = ['Original']\n",
    "testPredict = model.predict(X_test)\n",
    "testPredict = pd.DataFrame(scalerY.inverse_transform(testPredict.reshape(-1, 1)))\n",
    "testPredict.columns = ['Predicted']\n",
    "combined = pd.concat([ytest,testPredict],axis=1)\n",
    "combined.to_csv('ExtraTrees on Test data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "model = GradientBoostingRegressor()\n",
    "a = time.time()\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"Training time for GradientBoostingRegressor: \" + str(time.time()-a))\n",
    "testModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "model = IsolationForest()\n",
    "a = time.time()\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"Training time for IsolationForest: \" + str(time.time()-a))\n",
    "testModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "model = VotingRegressor()\n",
    "a = time.time()\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"Training time for VotingRegressor: \" + str(time.time()-a))\n",
    "testModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "model = HistGradientBoostingRegressor()\n",
    "a = time.time()\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"Training time for HistGradientBoostingRegressor: \" + str(time.time()-a))\n",
    "testModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainPredict = model.predict(X_train)\n",
    "ytrain = pd.DataFrame(scalerY.inverse_transform(Y_train.reshape(-1, 1)))\n",
    "ytrain.columns = ['Original']\n",
    "trainPredict = model.predict(X_train)\n",
    "trainPredict = pd.DataFrame(scalerY.inverse_transform(trainPredict.reshape(-1, 1)))\n",
    "trainPredict.columns = ['Predicted']\n",
    "combined = pd.concat([ytrain,trainPredict],axis=1)\n",
    "combined.to_csv('HistGradientBoosting on Train data.csv')\n",
    "\n",
    "#trainPredict = model.predict(X_train)\n",
    "ytest = pd.DataFrame(scalerY.inverse_transform(Y_test.reshape(-1, 1)))\n",
    "ytest.columns = ['Original']\n",
    "testPredict = model.predict(X_test)\n",
    "testPredict = pd.DataFrame(scalerY.inverse_transform(testPredict.reshape(-1, 1)))\n",
    "testPredict.columns = ['Predicted']\n",
    "combined = pd.concat([ytest,testPredict],axis=1)\n",
    "combined.to_csv('HistGradientBoosting on Test data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "model = DummyRegressor()\n",
    "a = time.time()\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"Training time for DummyRegressor: \" + str(time.time()-a))\n",
    "testModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "clf = linear_model.LassoLars(alpha=.1)\n",
    "a = time.time()\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "print(\"Training time for LassoLars: \" + str(time.time()-a))\n",
    "testModel(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_csv(link, usecols=[1,2,5,6,8,9,10,12,13,15,18,20,21,22,23], engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = read_csv(link, usecols=[1,2,5,6,8,9,10,12,13,15,18,20,21,22,23], engine='python')\n",
    "Y = read_csv(link, usecols=[7], engine='python')\n",
    "scalerX = MinMaxScaler(feature_range=(0, 1))\n",
    "scalerY = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scalerX.fit_transform(X)\n",
    "Y = scalerY.fit_transform(Y)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "look_back = 1\n",
    "#Y_train = create_dataset(Y_train,look_back)[1]\n",
    "#Y_test = create_dataset(Y_test,look_back)[1]\n",
    "\n",
    "X_train = numpy.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = numpy.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#CNN Model\n",
    "CNNmodel = Sequential()\n",
    "CNNmodel.add(Conv1D(filters=256, kernel_size=1, activation='tanh', input_shape=(look_back,X_train.shape[2])))\n",
    "CNNmodel.add(MaxPooling1D(pool_size=1))\n",
    "CNNmodel.add(Flatten())\n",
    "CNNmodel.add(Dropout(0.2))\n",
    "CNNmodel.add(Dense(50, activation='relu'))\n",
    "CNNmodel.add(Dense(1))\n",
    "CNNmodel.add(Activation('relu'))\n",
    "CNNmodel.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#fit model\n",
    "a = time.time()\n",
    "history = CNNmodel.fit(X_train, Y_train, epochs=15, verbose=2, batch_size=10)\n",
    "b = time.time()\n",
    "print(\"Train Time CNN: \" + str(b-a))\n",
    "#plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN\n",
    "LSTMmodel = Sequential()\n",
    "LSTMmodel.add(LSTM(16, input_shape=(None,X_train.shape[2])))\n",
    "LSTMmodel.add(Dropout(0.2))\n",
    "LSTMmodel.add(Dense(1, activation='softplus'))\n",
    "LSTMmodel.add(Activation('relu'))\n",
    "LSTMmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "a = time.time()\n",
    "history = LSTMmodel.fit(X_train, Y_train, epochs=30, batch_size=100, verbose=2)\n",
    "b = time.time()\n",
    "print(\"Train Time LSTM: \" + str(b-a))\n",
    "\n",
    "\n",
    "\n",
    "#CNN Model\n",
    "CNNmodel = Sequential()\n",
    "CNNmodel.add(Conv1D(filters=32, kernel_size=1, activation='tanh', input_shape=(1,1)))\n",
    "CNNmodel.add(MaxPooling1D(pool_size=1))\n",
    "CNNmodel.add(Flatten())\n",
    "CNNmodel.add(Dropout(0.2))\n",
    "CNNmodel.add(Dense(50, activation='relu'))\n",
    "CNNmodel.add(Dense(1))\n",
    "CNNmodel.add(Activation('relu'))\n",
    "CNNmodel.compile(optimizer='adam', loss='mean_squared_error')\n",
    "# fit model\n",
    "a = time.time()\n",
    "history = CNNmodel.fit(trainX, trainY, epochs=200, verbose=2, batch_size=10)\n",
    "b = time.time()\n",
    "print(\"Train Time CNN: \" + str(b-a))\n",
    "#plot_model(model)\n",
    "\n",
    "\n",
    "#MLP Model\n",
    "\n",
    "MLPmodel = Sequential()\n",
    "MLPmodel.add(Flatten())\n",
    "MLPmodel.add(Dropout(0.2))\n",
    "MLPmodel.add(Dense(1000,activation='relu', input_dim=1))\n",
    "MLPmodel.add(Dense(1))\n",
    "MLPmodel.compile(optimizer='adam', loss='mean_squared_error')\n",
    "# fit model\n",
    "#a = time.time()\n",
    "history = MLPmodel.fit(trainX, trainY, epochs=200, verbose=2, batch_size=10)\n",
    "b = time.time()\n",
    "print(\"Train Time MLP: \" + str(b-a))\n",
    "#plot_model(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "\n",
    "#RNN\n",
    "LSTMmodel = Sequential()\n",
    "LSTMmodel.add(LSTM(256))\n",
    "LSTMmodel.add(Dropout(0.2))\n",
    "LSTMmodel.add(Dense(1, activation='softplus'))\n",
    "LSTMmodel.add(Activation('relu'))\n",
    "LSTMmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "a = time.time()\n",
    "history = LSTMmodel.fit(X_train, Y_train, epochs=30, batch_size=100, verbose=1)\n",
    "b = time.time()\n",
    "print(\"Train Time LSTM: \" + str(b-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testModel(LSTMmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(Y)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict.reshape(trainPredict.shape[0],1)\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(Y)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)-1:len(Y)-1, :] = testPredict.reshape(testPredict.shape[0],1)\n",
    "\n",
    "predict = pd.DataFrame(testPredict)\n",
    "predict.columns = ['Data']\n",
    "predict['Type'] = 'Predicted'\n",
    "\n",
    "test = pd.DataFrame(Y_test)\n",
    "test.columns = ['Data']\n",
    "test[\"Type\"] = 'Original'\n",
    "\n",
    "y = pd.concat([predict,test], axis=0)\n",
    "y['Algorithm'] = 'LSTM'\n",
    "mixed = pd.DataFrame()\n",
    "mixed = pd.concat([mixed,y], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed[mixed['Algorithm'] == 'LSTM']\n",
    "lstm = mixed[mixed['Algorithm'] == 'LSTM']\n",
    "original = pd.DataFrame(lstm[lstm['Type'] == 'Original']['Data'])\n",
    "predicted = pd.DataFrame(lstm[lstm['Type'] == 'Predicted']['Data'])\n",
    "\n",
    "original = original.rename(columns={\"Data\":\"Original\"})\n",
    "predicted = predicted.rename(columns={\"Data\":\"Predicted\"})\n",
    "data2 = pd.concat([original,predicted], axis=1)\n",
    "\n",
    "p1 = min(predicted.values)[0]\n",
    "p2 = 0.4\n",
    "\n",
    "h1 = axes[0][0].hist2d(data=data2, x=\"Original\", y=\"Predicted\", bins=300, cmap=plt.cm.jet)\n",
    "axes[0][0].set_xlim(p1,p2)\n",
    "axes[0][0].set_ylim(p1,p2)\n",
    "axes[0][0].plot([p1,p2],[p1,p2], \"w-\")\n",
    "axes[0][0].set_ylabel(\"Predicted $\\longrightarrow$\", fontsize=14)\n",
    "axes[0][0].set_xlabel(\"Original $\\longrightarrow$\", fontsize=14)\n",
    "axes[0][0].set_title('LSTM', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cb = fig.colorbar(h4[3], ax=axes, location='bottom')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes[0][0].grid()\n",
    "axes[0][1].grid()\n",
    "axes[0][2].grid()\n",
    "axes[1][0].grid()\n",
    "axes[1][1].grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"Grid High Res.jpg\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.suptitle(\"Performances of all machine learning algorithms\", fontsize=16)\n",
    "axes[0][0].set_xticklabels(axes[0][0].get_xticklabels(),fontsize=12)\n",
    "axes[0][1].set_xticklabels(axes[0][1].get_xticklabels(),fontsize=12)\n",
    "axes[0][2].set_xticklabels(axes[0][2].get_xticklabels(),fontsize=12)\n",
    "axes[1][0].set_xticklabels(axes[1][0].get_xticklabels(),fontsize=12)\n",
    "axes[1][1].set_xticklabels(axes[1][1].get_xticklabels(),fontsize=12)\n",
    "axes[1][2].set_xticklabels(axes[1][2].get_xticklabels(),fontsize=12)\n",
    "axes[0][0].set_yticklabels(axes[0][0].get_yticklabels(),fontsize=12)\n",
    "axes[0][1].set_yticklabels(axes[0][1].get_yticklabels(),fontsize=12)\n",
    "axes[0][2].set_yticklabels(axes[0][2].get_yticklabels(),fontsize=12)\n",
    "axes[1][0].set_yticklabels(axes[1][0].get_yticklabels(),fontsize=12)\n",
    "axes[1][1].set_yticklabels(axes[1][1].get_yticklabels(),fontsize=12)\n",
    "axes[1][2].set_yticklabels(axes[1][2].get_yticklabels(),fontsize=12)\n",
    "\n",
    "axes[0][1].set_position([0.41, 0.5368181818181819, 0.228, 0.343])\n",
    "axes[0][2].set_position([0.7,0.5368181818181819,0.228,0.343])\n",
    "axes[1][0].set_position([0.24,0.1,0.228,0.343])\n",
    "axes[1][1].set_position([0.55,0.1,0.228,0.343])\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "#CNN Model\n",
    "CNNmodel = Sequential()\n",
    "CNNmodel.add(Conv1D(filters=256, kernel_size=1, activation='tanh'))\n",
    "CNNmodel.add(MaxPooling1D(pool_size=1))\n",
    "CNNmodel.add(Flatten())\n",
    "CNNmodel.add(Dropout(0.2))\n",
    "CNNmodel.add(Dense(50, activation='relu'))\n",
    "CNNmodel.add(Dense(1))\n",
    "CNNmodel.add(Activation('relu'))\n",
    "CNNmodel.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#fit model\n",
    "a = time.time()\n",
    "history = CNNmodel.fit(X_train, Y_train, epochs=30, verbose=1, batch_size=10)\n",
    "b = time.time()\n",
    "print(\"Train Time CNN: \" + str(b-a))\n",
    "#plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testModel(CNNmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(Y)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict.reshape(trainPredict.shape[0],1)\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(Y)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)-1:len(Y)-1, :] = testPredict.reshape(testPredict.shape[0],1)\n",
    "\n",
    "# plot baseline and predictions\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.plot(Y,label='Actual phytoplankton quantity', marker='o', color='blue',linewidth=2)\n",
    "plt.plot(trainPredictPlot, label='Determined by machine learning', marker='x',color='orange',linewidth=2)\n",
    "#plt.plot(testPredictPlot, label=\"Our Prediction\", marker='x',color='green',linewidth=2)\n",
    "plt.legend(loc=\"upper right\", fontsize=14)\n",
    "plt.xlim(28500,28700)\n",
    "plt.ylim(0,0.4)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel('Sub-section indexes of sample dataset $\\longrightarrow$', fontsize=16)\n",
    "plt.ylabel('Phytoplankton quantity \\n at normalized scale $\\longrightarrow$', fontsize=16)\n",
    "plt.title('Convolution Neural Network Regressor', fontsize=18)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig('Outputs/CNN.jpg',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "model_svr = SVR(kernel='linear', degree=2)\n",
    "a = time.time()\n",
    "model_svr.fit(X_train, Y_train.ravel())\n",
    "print(\"Training time for SVR: \" + str(time.time()-a))\n",
    "testModel(model_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(Y)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict.reshape(trainPredict.shape[0],1)\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(Y)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)-1:len(Y)-1, :] = testPredict.reshape(testPredict.shape[0],1)\n",
    "\n",
    "predict = pd.DataFrame(testPredict)\n",
    "predict.columns = ['Data']\n",
    "predict['Type'] = 'Predicted'\n",
    "\n",
    "test = pd.DataFrame(Y_test)\n",
    "test.columns = ['Data']\n",
    "test[\"Type\"] = 'Original'\n",
    "\n",
    "y = pd.concat([predict,test], axis=0)\n",
    "y['Algorithm'] = 'SVR'\n",
    "mixed = pd.DataFrame()\n",
    "mixed = pd.concat([mixed,y], axis = 0)\n",
    "#sns.lmplot(x='index', y='Data', hue='Type', data=mixed, palette=\"Set1\", height=4, aspect=2.5, x_jitter=0.1, markers=['o','X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed[mixed['Algorithm'] == 'SVR']\n",
    "svr = mixed[mixed['Algorithm'] == 'SVR']\n",
    "original = pd.DataFrame(svr[svr['Type'] == 'Original']['Data'])\n",
    "predicted = pd.DataFrame(svr[svr['Type'] == 'Predicted']['Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = original.rename(columns={\"Data\":\"Original\"})\n",
    "predicted = predicted.rename(columns={\"Data\":\"Predicted\"})\n",
    "data2 = pd.concat([original,predicted], axis=1)\n",
    "\n",
    "p1 = min(predicted.values)[0]\n",
    "p2 = 0.4\n",
    "\n",
    "h1 = axes[0][1].hist2d(data=data2, x=\"Original\", y=\"Predicted\", bins=300, cmap=plt.cm.jet)\n",
    "axes[0][1].set_xlim(p1,p2)\n",
    "axes[0][1].set_ylim(p1,p2)\n",
    "axes[0][1].plot([p1,p2],[p1,p2], \"w-\")\n",
    "axes[0][1].set_ylabel(\"Predicted $\\longrightarrow$\", fontsize=14)\n",
    "axes[0][1].set_xlabel(\"Original $\\longrightarrow$\", fontsize=14)\n",
    "axes[0][1].set_title('SVR', fontsize=14)\n",
    "#plt.pcolormesh(data = h[3])\n",
    "#fig.colorbar(h[3], ax=axes, location='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed[mixed['Algorithm'] == 'SVR']\n",
    "svr = mixed[mixed['Algorithm'] == 'SVR']\n",
    "original = svr[svr['Type'] == 'Original']['Data']\n",
    "predicted = svr[svr['Type'] == 'Predicted']['Data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = pd.DataFrame(trainPredict[200:700])\n",
    "predict.columns = ['Data']\n",
    "predict['Type'] = 'Original'\n",
    "predict = predict.reset_index()\n",
    "sns.regplot(x='index', y='Data', data=predict, x_jitter=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "clf = tree.DecisionTreeRegressor()\n",
    "a = time.time()\n",
    "clf = clf.fit(X_train,  Y_train)\n",
    "print(\"Training time for DTR: \" + str(time.time()-a))\n",
    "testModel(clf)\n",
    "#evaluate_model(clf, x_test_svr, y_test_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(Y)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict.reshape(trainPredict.shape[0],1)\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(Y)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)-1:len(Y)-1, :] = testPredict.reshape(testPredict.shape[0],1)\n",
    "\n",
    "\n",
    "predict = pd.DataFrame(testPredict)\n",
    "predict.columns = ['Data']\n",
    "predict['Type'] = 'Predicted'\n",
    "\n",
    "test = pd.DataFrame(Y_test)\n",
    "test.columns = ['Data']\n",
    "test[\"Type\"] = 'Original'\n",
    "\n",
    "y = pd.concat([predict,test], axis=0)\n",
    "y['Algorithm'] = 'DTR'\n",
    "mixed = pd.DataFrame()\n",
    "mixed = pd.concat([mixed,y], axis = 0)\n",
    "#sns.lmplot(x='index', y='Data', hue='Type', data=mixed, palette=\"Set1\", height=4, aspect=2.5, x_jitter=0.1, markers=['o','X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed[mixed['Algorithm'] == 'DTR']\n",
    "dtr = mixed[mixed['Algorithm'] == 'DTR']\n",
    "original = pd.DataFrame(dtr[dtr['Type'] == 'Original']['Data'])\n",
    "predicted = pd.DataFrame(dtr[dtr['Type'] == 'Predicted']['Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = original.rename(columns={\"Data\":\"Original\"})\n",
    "predicted = predicted.rename(columns={\"Data\":\"Predicted\"})\n",
    "data2 = pd.concat([original,predicted], axis=1)\n",
    "\n",
    "p1 = min(predicted.values)[0]\n",
    "p2 = 0.4\n",
    "\n",
    "h2 = axes[0][2].hist2d(data=data2, x=\"Original\", y=\"Predicted\", bins=300, cmap=plt.cm.jet)\n",
    "axes[0][2].set_xlim(p1,p2)\n",
    "axes[0][2].set_ylim(p1,p2)\n",
    "axes[0][2].plot([p1,p2],[p1,p2], \"w-\")\n",
    "axes[0][2].set_ylabel(\"Predicted $\\longrightarrow$\", fontsize=14)\n",
    "axes[0][2].set_xlabel(\"Original $\\longrightarrow$\", fontsize=14)\n",
    "axes[0][2].set_title('DTR', fontsize=14)\n",
    "#plt.pcolormesh(data = h[3])\n",
    "#fig.colorbar(h[3], ax=axes, location='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "clf = linear_model.LassoLars(alpha=.1)\n",
    "a = time.time()\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "print(\"Training time for LassoLars: \" + str(time.time()-a))\n",
    "testModel(clf)\n",
    "#evaluate_model(clf, x_test_svr, y_test_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(Y)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict.reshape(trainPredict.shape[0],1)\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(Y)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)-1:len(Y)-1, :] = testPredict.reshape(testPredict.shape[0],1)\n",
    "\n",
    "# plot baseline and predictions\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.plot(Y,label='Actual phytoplankton quantity', marker='o', color='blue',linewidth=2)\n",
    "plt.plot(trainPredictPlot, label='Determined by machine learning', marker='x',color='orange',linewidth=2)\n",
    "#plt.plot(testPredictPlot, label=\"Our Prediction\", marker='x',color='green',linewidth=2)\n",
    "plt.legend(loc=\"upper right\", fontsize=14)\n",
    "plt.xlim(28500,28700)\n",
    "plt.ylim(0,0.4)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel('Sub-section indexes of sample dataset $\\longrightarrow$', fontsize=16)\n",
    "plt.ylabel('Phytoplankton quantity \\n at normalized scale $\\longrightarrow$', fontsize=16)\n",
    "plt.title('Lasso Least Angle Regressor', fontsize=18)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig('Outputs/LassoLars.jpg',dpi=600)\n",
    "plt.show()\n",
    "\n",
    "predict = pd.DataFrame(trainPredict[700:1200])\n",
    "predict.columns = ['Data']\n",
    "predict['Type'] = 'Original'\n",
    "\n",
    "train = pd.DataFrame(Y_train[700:1200])\n",
    "train.columns = ['Data']\n",
    "train[\"Type\"] = 'Predicted'\n",
    "\n",
    "y = pd.concat([predict,train], axis=0)\n",
    "y['Algorithm'] = 'LassoLars'\n",
    "mixed = pd.concat([mixed,y], axis = 0)\n",
    "#sns.lmplot(x='index', y='Data', hue='Type', data=mixed, palette=\"Set1\", height=4, aspect=2.5, x_jitter=0.1, markers=['o','X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "clf = linear_model.BayesianRidge()\n",
    "a = time.time()\n",
    "a = time.time()\n",
    "clf = clf.fit(X_train, Y_train.ravel())\n",
    "b = time.time()\n",
    "print(\"Train time for BayesianRidge:\" + str(b-a))\n",
    "testModel(clf)\n",
    "#evaluate_model(clf, x_test_svr, y_test_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(Y)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict.reshape(trainPredict.shape[0],1)\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(Y)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)-1:len(Y)-1, :] = testPredict.reshape(testPredict.shape[0],1)\n",
    "\n",
    "# plot baseline and predictions\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.plot(Y,label='Actual phytoplankton quantity', marker='o', color='blue',linewidth=2)\n",
    "plt.plot(trainPredictPlot, label='Determined by machine learning', marker='x',color='orange',linewidth=2)\n",
    "#plt.plot(testPredictPlot, label=\"Our Prediction\", marker='x',color='green',linewidth=2)\n",
    "plt.legend(loc=\"upper right\", fontsize=14)\n",
    "plt.xlim(28500,28700)\n",
    "plt.ylim(0,0.4)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel('Sub-section indexes of sample dataset $\\longrightarrow$', fontsize=16)\n",
    "plt.ylabel('Phytoplankton quantity \\n at normalized scale $\\longrightarrow$', fontsize=16)\n",
    "plt.title('Bayesian Ridge Regressor', fontsize=18)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig('Outputs/BayesianRidge.jpg',dpi=600)\n",
    "plt.show()\n",
    "\n",
    "predict = pd.DataFrame(trainPredict[700:1200])\n",
    "predict.columns = ['Data']\n",
    "predict['Type'] = 'Original'\n",
    "\n",
    "train = pd.DataFrame(Y_train[700:1200])\n",
    "train.columns = ['Data']\n",
    "train[\"Type\"] = 'Predicted'\n",
    "\n",
    "y = pd.concat([predict,train], axis=0)\n",
    "y['Algorithm'] = 'Bayesian Ridge'\n",
    "mixed = pd.concat([mixed,y], axis = 0)\n",
    "#sns.lmplot(x='index', y='Data', hue='Type', data=mixed, palette=\"Set1\", height=4, aspect=2.5, x_jitter=0.1, markers=['o','X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "clf = Pipeline([('poly', PolynomialFeatures(degree=3)),('linear', LinearRegression(fit_intercept=False))])\n",
    "a = time.time()\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "print(\"Training time for Pipeline Linear Regression: \" + str(time.time()-a))\n",
    "testModel(clf)\n",
    "#evaluate_model(clf, x_test_svr, y_test_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(Y)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict.reshape(trainPredict.shape[0],1)\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(Y)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)-1:len(Y)-1, :] = testPredict.reshape(testPredict.shape[0],1)\n",
    "\n",
    "\n",
    "predict = pd.DataFrame(testPredict)\n",
    "predict.columns = ['Data']\n",
    "predict['Type'] = 'Original'\n",
    "\n",
    "test = pd.DataFrame(Y_test)\n",
    "test.columns = ['Data']\n",
    "test[\"Type\"] = 'Predicted'\n",
    "\n",
    "y = pd.concat([predict,test], axis=0)\n",
    "y['Algorithm'] = 'Pipelined'\n",
    "mixed = pd.DataFrame()\n",
    "mixed = pd.concat([y,mixed], axis = 0)\n",
    "#sns.lmplot(x='index', y='Data', hue='Type', data=mixed, palette=\"Set1\", height=4, aspect=2.5, x_jitter=0.1, markers=['o','X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed[mixed['Algorithm'] == 'Pipelined']\n",
    "pipeline = mixed[mixed['Algorithm'] == 'Pipelined']\n",
    "original = pd.DataFrame(pipeline[pipeline['Type'] == 'Original']['Data'])\n",
    "predicted = pd.DataFrame(pipeline[pipeline['Type'] == 'Predicted']['Data'])\n",
    "\n",
    "original = original.rename(columns={\"Data\":\"Original\"})\n",
    "predicted = predicted.rename(columns={\"Data\":\"Predicted\"})\n",
    "data2 = pd.concat([original,predicted], axis=1)\n",
    "\n",
    "h3 = axes[1][0].hist2d(data=data2, x=\"Original\", y=\"Predicted\", bins=300, cmap=plt.cm.jet)\n",
    "axes[1][0].set_xlim(p1,p2)\n",
    "axes[1][0].set_ylim(p1,p2)\n",
    "axes[1][0].plot([p1,p2],[p1,p2], \"w-\")\n",
    "axes[1][0].set_ylabel(\"Predicted $\\longrightarrow$\", fontsize=14)\n",
    "axes[1][0].set_xlabel(\"Original $\\longrightarrow$\", fontsize=14)\n",
    "axes[1][0].set_title('Pipelined', fontsize=14)\n",
    "#plt.pcolormesh(data = h[3])\n",
    "#fig.colorbar(h[3], ax=axes, location='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "clf = KNeighborsRegressor(n_neighbors=3)\n",
    "a = time.time()\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "print(\"Training time for KNR: \" + str(time.time()-a))\n",
    "testModel(clf)\n",
    "#evaluate_model(clf, x_test_svr, y_test_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(Y)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict.reshape(trainPredict.shape[0],1)\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(Y)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)-1:len(Y)-1, :] = testPredict.reshape(testPredict.shape[0],1)\n",
    "\n",
    "# plot baseline and predictions\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.plot(Y,label='Actual phytoplankton quantity', marker='o', color='blue',linewidth=2)\n",
    "plt.plot(trainPredictPlot, label='Determined by machine learning', marker='x',color='orange',linewidth=2)\n",
    "#plt.plot(testPredictPlot, label=\"Our Prediction\", marker='x',color='green',linewidth=2)\n",
    "plt.legend(loc=\"upper right\", fontsize=14)\n",
    "plt.xlim(28500,28700)\n",
    "plt.ylim(0,0.4)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel('Sub-section indexes of sample dataset $\\longrightarrow$', fontsize=16)\n",
    "plt.ylabel('Phytoplankton quantity \\n at normalized scale $\\longrightarrow$', fontsize=16)\n",
    "plt.title('K-Neighbor Regressor', fontsize=18)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig('Outputs/KNR.jpg',dpi=600)\n",
    "plt.show()\n",
    "\n",
    "predict = pd.DataFrame(trainPredict[700:1200])\n",
    "predict.columns = ['Data']\n",
    "predict['Type'] = 'Original'\n",
    "\n",
    "train = pd.DataFrame(Y_train[700:1200])\n",
    "train.columns = ['Data']\n",
    "train[\"Type\"] = 'Predicted'\n",
    "\n",
    "y = pd.concat([predict,train], axis=0)\n",
    "y['Algorithm'] = 'KNR'\n",
    "mixed = pd.concat([mixed,y], axis = 0)\n",
    "#sns.lmplot(x='index', y='Data', hue='Type', data=mixed, palette=\"Set1\", height=4, aspect=2.5, x_jitter=0.1, markers=['o','X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "clf = MLPRegressor(random_state=1, max_iter=10000)\n",
    "clf = clf.fit(X_train, Y_train.ravel())\n",
    "print(\"Training time for MLPR: \" + str(time.time()-a))\n",
    "testModel(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = numpy.empty_like(Y)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict.reshape(trainPredict.shape[0],1)\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(Y)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)-1:len(Y)-1, :] = testPredict.reshape(testPredict.shape[0],1)\n",
    "\n",
    "predict = pd.DataFrame(testPredict)\n",
    "predict.columns = ['Data']\n",
    "predict['Type'] = 'Predicted'\n",
    "\n",
    "test = pd.DataFrame(Y_test)\n",
    "test.columns = ['Data']\n",
    "test[\"Type\"] = 'Original'\n",
    "\n",
    "y = pd.concat([predict,test], axis=0)\n",
    "y['Algorithm'] = 'MLPR'\n",
    "mixed = pd.DataFrame()\n",
    "mixed = pd.concat([y, mixed], axis = 0)\n",
    "#sns.lmplot(x='index', y='Data', hue='Type', data=mixed, palette=\"Set1\", height=4, aspect=2.5, x_jitter=0.1, markers=['o','X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess()\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape(nsamples,nx*ny)\n",
    "\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape(nsamples,nx*ny)\n",
    "\n",
    "clf = RandomForestRegressor()\n",
    "clf = clf.fit(X_train, Y_train.ravel())\n",
    "print(\"Training time for RFR: \" + str(time.time()-a))\n",
    "testModel(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed[mixed['Algorithm'] == 'MLPR']\n",
    "mlpr = mixed[mixed['Algorithm'] == 'MLPR']\n",
    "#mlpr = mlpr.replace(0, np.nan, inplace=True)\n",
    "original = pd.DataFrame(mlpr[mlpr['Type'] == 'Original']['Data'])\n",
    "predicted = pd.DataFrame(mlpr[mlpr['Type'] == 'Predicted']['Data'])\n",
    "\n",
    "original = original.rename(columns={\"Data\":\"Original\"})\n",
    "predicted = predicted.rename(columns={\"Data\":\"Predicted\"})\n",
    "data2 = pd.concat([original,predicted], axis=1)\n",
    "\n",
    "p1 = min(predicted.values)\n",
    "h4 = axes[1][1].hist2d(data=data2, x=\"Original\", y=\"Predicted\", bins=300, cmap=cmap)\n",
    "axes[1][1].set_xlim(p1,p2)\n",
    "axes[1][1].set_ylim(p1,p2)\n",
    "axes[1][1].plot([p1,p2],[p1,p2], \"r-\")\n",
    "axes[1][1].plot([p3,p4],[p3,p4], \"g-\")\n",
    "axes[1][1].set_ylabel(\"Predicted $\\longrightarrow$\", fontsize=14)\n",
    "axes[1][1].set_xlabel(\"Original $\\longrightarrow$\", fontsize=14)\n",
    "axes[1][1].set_title('MLPR', fontsize=14)\n",
    "\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = numpy.array(original['Original'])\n",
    "y1 = numpy.array(predicted['Predicted'])\n",
    "coef = np.polyfit(x1,y1,1)\n",
    "p3,p4 = np.poly1d(coef) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.cm.jet\n",
    "cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "cmaplist[0] = (1.0,1.0,1.0,1.0)\n",
    "cmap = mlp.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_patch = mlp.patches.Patch(color='red', label='The red data')\n",
    "blue_patch = mlp.patches.Patch(color='blue', label='The blue data')\n",
    "fig.legend(handles=[red_patch, blue_patch])\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
